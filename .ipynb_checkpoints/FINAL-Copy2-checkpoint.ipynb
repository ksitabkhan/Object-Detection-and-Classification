{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import PIL.Image as Image\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import pathlib\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install bing-image-downloader\n",
    "# from bing_image_downloader import downloader\n",
    "# query_string=\"sedan\"\n",
    "# downloader.download(query_string, limit=500,  output_dir='dataset', adult_filter_off=True, force_replace=False, timeout=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_string=\"suv\"\n",
    "# downloader.download(query_string, limit=500,  output_dir='dataset', adult_filter_off=True, force_replace=False, timeout=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image count in Data set is  1147\n"
     ]
    }
   ],
   "source": [
    "CONFIDENCE= 0.5\n",
    "SCORE_THRESHOLD = 0.5\n",
    "IOU_THRESHOLD = 0.5\n",
    "configPath= \"C:\\\\Users\\khadija sitabkhan\\Documents\\Assignments\\Case_Studies\\yolov4-tiny.cfg\"\n",
    "weightsPath= \"C:\\\\Users\\khadija sitabkhan\\Documents\\Assignments\\Case_Studies\\yolov4-tiny.weights\"\n",
    "font_scale=1\n",
    "thickness = 1\n",
    "IMAGE_SHAPE=(224,224)\n",
    "#classifier = tf.keras.Sequential([hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\", input_shape=IMAGE_SHAPE+(3,))])\n",
    "model=[]\n",
    "\n",
    "\n",
    "Image_labels = []\n",
    "with open(\"ImageNet_Labels.txt\",\"r\") as f:\n",
    "    Image_labels = f.read().splitlines()\n",
    "\n",
    "#      TrainClassifier()\n",
    "data_dir=pathlib.Path(\".\\\\dataset\")\n",
    "image_count = len(list(data_dir.glob('*/*g')))\n",
    "print(\"Image count in Data set is \",image_count)\n",
    "sedan = list(data_dir.glob('sedan/*'))\n",
    "suv = list(data_dir.glob('suv/*'))\n",
    "car_dictionary = {\n",
    "    'suv' : list(data_dir.glob(\"suv/*\")),\n",
    "    'sedan': list(data_dir.glob(\"sedan/*\"))\n",
    "}\n",
    "car_label_dictionary = {\n",
    "    'sedan' : 0,\n",
    "    'suv' : 1\n",
    "}\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "X, y = [], []\n",
    "for car_name, images in car_dictionary.items():\n",
    "    for image in images:\n",
    "        img = cv2.imread(str(image))\n",
    "        resized_img = cv2.resize(img,IMAGE_SHAPE)\n",
    "        X.append(resized_img)\n",
    "        y.append(car_label_dictionary[car_name])\n",
    "X=np.array(X)\n",
    "y=np.array(y)\n",
    "X_train,X_test , y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "X_train_scaled= X_train/255\n",
    "X_test_scaled = X_test/255\n",
    "feature_extracter_model = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "pretrained_model_without_top_layer = hub.KerasLayer(\n",
    "    feature_extracter_model, input_shape=(224, 224, 3), trainable=False)\n",
    "num_of_cars = 2\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    pretrained_model_without_top_layer,\n",
    "    tf.keras.layers.Dense(num_of_cars)\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "model.compile(  \n",
    "optimizer=\"adam\",\n",
    "loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "metrics=['acc'])\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestDataSet(X_test,_y_test):\n",
    "    print(\"now evaluating the trained model\")\n",
    "    model.evaluate(X_test_scaled,y_test)\n",
    "\n",
    "def Predict(X):\n",
    "    predicted = model.predict(X[np.newaxis, ...])\n",
    "    predicted = np.argmax(predicted, axis=1)\n",
    "    return ([k for k, v in car_label_dictionary.items() if v == predicted])\n",
    "#         Image_labels[722]\n",
    "#class object_detection(object_classification):\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = open(\"coco.names\").read().strip().split(\"\\n\")\n",
    "colors = np.random.randint(0, 255, size=(len(labels), 3), dtype=\"uint8\")\n",
    "net = cv2.dnn.readNetFromDarknet(configPath, weightsPath)\n",
    "ln = net.getLayerNames()\n",
    "ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadVideo():\n",
    "    car_counter=[]\n",
    "    video_file = \"assignment-clip.mp4\"\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    _, image = cap.read()\n",
    "    h, w = image.shape[:2]\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "    out = cv2.VideoWriter(\"output.avi\", fourcc, 30.0, (w, h))\n",
    "    \n",
    "    sedan_counter=[]\n",
    "    suv_counter=[]\n",
    "    frame_counter=[]\n",
    "    frame_number=0\n",
    "    while True:\n",
    "        ret, image = cap.read()\n",
    "        if ret==True:\n",
    "            frame_number +=1\n",
    "            h, w = image.shape[:2]\n",
    "            blob = cv2.dnn.blobFromImage(image, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "            net.setInput(blob)\n",
    "            start = time.perf_counter()\n",
    "            layer_outputs = net.forward(ln)\n",
    "            time_took = time.perf_counter() - start\n",
    "#                 print(\"Time took:\", time_took)\n",
    "            boxes, confidences, class_ids = [], [], []\n",
    "            for output in layer_outputs:\n",
    "                # loop over each of the object detections\n",
    "                for detection in output:\n",
    "                    # extract the class id (label) and confidence (as a probability) of\n",
    "                    # the current object detection\n",
    "                    scores = detection[5:]\n",
    "                    class_id = np.argmax(scores)\n",
    "                    confidence = scores[class_id]\n",
    "                    # discard weak predictions by ensuring the detected\n",
    "                    # probability is greater than the minimum probability\n",
    "                    if confidence > CONFIDENCE:\n",
    "                        # scale the bounding box coordinates back relative to the\n",
    "                        # size of the image, keeping in mind that YOLO actually\n",
    "                        # returns the center (x, y)-coordinates of the bounding\n",
    "                        # box followed by the boxes' width and height\n",
    "                        box = detection[:4] * np.array([w, h, w, h])\n",
    "                        (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "            \n",
    "                        # use the center (x, y)-coordinates to derive the top and\n",
    "                        # and left corner of the bounding box\n",
    "                        x = int(centerX - (width / 2))\n",
    "                        y = int(centerY - (height / 2))\n",
    "            \n",
    "                        # update our list of bounding box coordinates, confidences,\n",
    "                        # and class IDs\n",
    "                        boxes.append([x, y, int(width), int(height)])\n",
    "                        confidences.append(float(confidence))\n",
    "                        class_ids.append(class_id)                \n",
    "            # perform the non maximum suppression given the scores defined before\n",
    "            idxs = cv2.dnn.NMSBoxes(boxes, confidences, SCORE_THRESHOLD, IOU_THRESHOLD)\n",
    "        \n",
    "            font_scale = 1\n",
    "            thickness = 1\n",
    "            sedan=0\n",
    "            suv=0\n",
    "            car_per_frame=0\n",
    "            # ensure at least one detection exists\n",
    "            if len(idxs) > 0:\n",
    "                \n",
    "                # loop over the indexes we are keeping\n",
    "                for i in idxs.flatten():\n",
    "                    # extract the bounding box coordinates\n",
    "                    x, y = boxes[i][0], boxes[i][1]\n",
    "                    w, h = boxes[i][2], boxes[i][3]\n",
    "                    # draw a bounding box rectangle and label on the image\n",
    "                    color = [int(c) for c in colors[class_ids[i]]]\n",
    "                    cv2.rectangle(image, (x, y), (x + w, y + h), color=color, thickness=thickness)\n",
    "                    \n",
    "                        \n",
    "                    text = f\"{labels[class_ids[i]]}: {confidences[i]:.2f}\"\n",
    "                    if (labels[class_ids[i]== \"car\"]):\n",
    "                        car_per_frame += 1\n",
    "                        cropped_img = image[y:y+h, x:x+w]\n",
    "                        cropped_img=cropped_img/255\n",
    "                        try:\n",
    "                            cropped_img = cv2.resize(cropped_img,(224,224),cv2.INTER_AREA)\n",
    "                            class_name= Predict(cropped_img)\n",
    "#                             print(\"class_name\", class_name)\n",
    "                            if (class_name[0]==\"sedan\"):\n",
    "                                sedan +=1\n",
    "                            else:\n",
    "                                suv +=1\n",
    "                        except:\n",
    "                            break\n",
    "                    #                         print(\"frame number is \",i,\" labels is \", labels[class_ids[i]])\n",
    "                    # calculate text width & height to draw the transparent boxes as background of the text\n",
    "                    (text_width, text_height) = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, fontScale=font_scale, thickness=thickness)[0]\n",
    "                    text_offset_x = x\n",
    "                    text_offset_y = y - 5\n",
    "                    box_coords = ((text_offset_x, text_offset_y), (text_offset_x + text_width + 2, text_offset_y - text_height))\n",
    "                    overlay = image.copy()\n",
    "                    #print(\"type overlay\", type(overlay))\n",
    "                    cv2.rectangle(overlay, box_coords[0], box_coords[1], color=color, thickness=cv2.FILLED)\n",
    "                    \n",
    "                    # add opacity (transparency to the box)\n",
    "                    image = cv2.addWeighted(overlay, 0.6, image, 0.4, 0)\n",
    "                    # now put the text (label: confidence %)\n",
    "                    cv2.putText(image, class_name[0], (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        fontScale=font_scale, color=(0, 0, 0), thickness=thickness)\n",
    "#                     print(\"car_count is \", car_per_frame)\n",
    "            frame_counter.append(frame_number)\n",
    "            car_counter.append(car_per_frame)\n",
    "            sedan_counter.append(sedan)\n",
    "            suv_counter.append(suv)\n",
    "            out.write(image)\n",
    "#                 print(\"type(image) \", type(image))\n",
    "#                 cv2.imshow(\"image\", image)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                break\n",
    "        else:\n",
    "            print(\"\\n\\ncar_counter is \", car_counter)\n",
    "            print(\"\\n\\nsedan counter\", sedan_counter)\n",
    "            print(\"\\n\\nsuv counter is \", suv_counter)\n",
    "            Predicted_values = pd.DataFrame({'frame_number' : frame_counter,\n",
    "                                'suv_predicted' : suv_counter,\n",
    "                                'sedan_predicted' : sedan_counter,\n",
    "                                'total_predicted' : np.add(suv_counter,sedan_counter) }, \n",
    "                                columns=['frame_number','suv_predicted','sedan_predicted', 'total_predicted'])\n",
    "            return Predicted_values\n",
    "            break    \n",
    "    \n",
    "#         \n",
    "#         cv2.destroyAllWindows()           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "print(\"----------------------------------#4 complete\",datetime.now().strftime(\"%H:%M:%S\"))\n",
    "predicted=LoadVideo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ground_Truth = pd.read_excel (r'Groundtruth.xlsx')\n",
    "ground_Truth\n",
    "ground_Truth.drop(ground_Truth.head(1).index,inplace=True)\n",
    "ground_Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted[\"total_predicted\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "F1_TOTAL =f1_score(ground_Truth[\"Total\"], predicted[\"total_predicted\"], average='weighted')\n",
    "    \n",
    "print(f\"f1 score of the object detection algorithm is {round(F1_TOTAL*100,2)}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1_SUV =f1_score(ground_Truth[\"SUV\"], predicted[\"suv_predicted\"], average='weighted')\n",
    "print(f\"f1 score of the SUV cars detected in the classification algorithm is  {round(F1_SUV*100,2)}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1_SEDAN =f1_score(ground_Truth[\"Sedan\"], predicted[\"sedan_predicted\"], average='weighted')\n",
    "print(f\"f1 score of the sedan cars detected in the classification algorithm is {round(F1_SEDAN*100,2)}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
